{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Zhijun\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.115 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "D:\\abc\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "D:\\abc\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from helper import *\n",
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ff_train = pd.read_csv('ff_train.csv', encoding = 'utf-8')\n",
    "mg_train = pd.read_csv('mg_train.csv', encoding = 'utf-8')\n",
    "mf_train = pd.read_csv('mf_train.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1  Create features indicating name entity of each keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def get_pos_info(df, key):\n",
    "#    pos_list = []\n",
    "#    n = 0\n",
    "#    for name in df['Product_Name_s'].tolist():\n",
    "#        n += 1\n",
    "#        if key in name.strip().split():\n",
    "#            pos_list.append((name.strip().split().index(key)+1)/len(name.strip().split()))\n",
    "#    if len(pos_list) < 1:\n",
    "#        pos_list = [0]\n",
    "#    min_pos, max_pos, mean_pos, idf = min(pos_list), max(pos_list), sum(pos_list)/len(pos_list), math.log(n/(len(pos_list)+1))\n",
    "#    return min_pos, max_pos, mean_pos, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_info(df, w2vmodel):\n",
    "    word_info = {}\n",
    "    model, keys, wordvector = read_word2vec(w2vmodel)\n",
    "    for key in keys:\n",
    "        min_pos, max_pos, mean_pos, idf = get_pos_info(df, key)\n",
    "        word_info[key] = np.array((min_pos, max_pos, mean_pos, idf))\n",
    "    return word_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_info_mg = get_word_info(mg_train, 'model_mg')\n",
    "word_info_ff = get_word_info(ff_train, 'model_ff')\n",
    "word_info_mf = get_word_info(mf_train, 'model_mf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Create features indicating the position of a keyword in a particular sentence  &\n",
    "#### 1.3 Dimensionality reduction (PCA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_input_X(df, word2vec_file, word_info):\n",
    "    \n",
    "    model, keys, wordvector = read_word2vec(word2vec_file)\n",
    "    \n",
    "    df['product_length'] = df.apply(lambda row: len(split_words(row['Product_Name_s'], mode = 'simplified')), axis = 1)\n",
    "    df['query_length'] = df.apply(lambda row: len(split_words(row['Query_s'], mode = 'simplified')), axis = 1)\n",
    "    df['min_pos'] = df.apply(lambda row: find_keyword_info(row['Query_s'], row['Product_Name_s'], 'min_pos', keys, word_info), axis = 1)\n",
    "    df['max_pos'] = df.apply(lambda row: find_keyword_info(row['Query_s'], row['Product_Name_s'], 'max_pos', keys, word_info), axis = 1)\n",
    "    df['mean_pos'] = df.apply(lambda row: find_keyword_info(row['Query_s'], row['Product_Name_s'], 'mean_pos', keys, word_info), axis = 1)\n",
    "    df['tf'] = df.apply(lambda row: find_keyword_info(row['Query_s'], row['Product_Name_s'], 'tf', keys, word_info), axis = 1)\n",
    "    df['tmin_pos'] = df.apply(lambda row: find_keyword_info(row['Query_s'], row['Product_Name_s'], 'tmin_pos', keys, word_info), axis = 1)\n",
    "    df['tmax_pos'] = df.apply(lambda row: find_keyword_info(row['Query_s'], row['Product_Name_s'], 'tmax_pos', keys, word_info), axis = 1)\n",
    "    df['tmean_pos'] = df.apply(lambda row: find_keyword_info(row['Query_s'], row['Product_Name_s'], 'tmean_pos', keys, word_info), axis = 1)   \n",
    "    df['idf'] = df.apply(lambda row: find_keyword_info(row['Query_s'], row['Product_Name_s'], 'idf', keys, word_info), axis = 1)\n",
    "    df['tfidf'] = df['tf'] * df['idf']\n",
    "    df['min_pos_por'] = df['min_pos'] / df['product_length']\n",
    "    df['max_pos_por'] = df['max_pos'] / df['product_length']\n",
    "    df['mean_pos_por'] = df['mean_pos'] / df['product_length']\n",
    "\n",
    "    lines = []\n",
    "    for i in range(df.shape[0]):\n",
    "        product_vec = vectorizer(df['Product_Name_s'].tolist()[i], model, keys, wordvector)\n",
    "        query_vec = vectorizer(df['Query_s'].tolist()[i], model, keys, wordvector)\n",
    "        lines.append(list(product_vec) + list(query_vec))\n",
    "    \n",
    "    X = pd.DataFrame(lines)\n",
    "    pca = PCA(n_components = 200)\n",
    "    X = pd.DataFrame(pca.fit_transform(X))\n",
    "\n",
    "    \n",
    "    X = pd.concat([X.reset_index(drop=True), df[['product_length', 'query_length', 'min_pos', 'max_pos', 'mean_pos','tf', 'tmin_pos', 'tmax_pos', 'tmean_pos', 'idf', 'tfidf','min_pos_por', 'max_pos_por', 'mean_pos_por']]], axis=1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_input_y(df):\n",
    "    return np.where((df['num_of_clicks'] > 0), 1, 0).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_mg = construct_input_X(mg_train, 'model_mg', word_info_mg)\n",
    "y_mg = construct_input_y(mg_train)\n",
    "X_ff = construct_input_X(ff_train, 'model_ff', word_info_ff)\n",
    "y_ff = construct_input_y(ff_train)\n",
    "X_mf = construct_input_X(mf_train, 'model_mf', word_info_mf)\n",
    "y_mf = construct_input_y(mf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4169, 214)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train supervised learning model\n",
    "Default choice is to train both lightgbm and svm models, and the best set of parameters would be selected by using cross validation, based on F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_training(X, y, models = ['lgb', 'svm'], scoring = 'f1', random_state = 0):\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=random_state)\n",
    "\n",
    "    opt_params = {}\n",
    "    \n",
    "    #LR model\n",
    "    if 'lr' in models:\n",
    "        print('Start training Logistics Regression model.')\n",
    "        start = time.time()\n",
    "        clf = linear_model.Lasso(random_state=random_state)\n",
    "        param_grid_clf = {'alpha': [0.1**i for i in range(1, 6)]}\n",
    "        grid_clf = GridSearchCV(clf, param_grid_clf, cv=5, scoring=scoring)\n",
    "        grid_clf.fit(X_train, y_train)\n",
    "        print(\"Completed. Time_used: \" + str(int(time.time()-start)) + 's, best score: ' + str(grid_clf.best_score_))\n",
    "        opt_params['clf'] = grid_clf.best_params_\n",
    "    \n",
    "    #print(\"\\n\")\n",
    "    \n",
    "    #RF model\n",
    "    if 'rf' in models:\n",
    "        print('Start training Random Forest model.')\n",
    "        start = time.time()\n",
    "        rf = RandomForestClassifier(random_state=random_state, n_jobs = -1)\n",
    "        param_grid_rf = { \n",
    "            'n_estimators': [200*i for i in range(1, 6)],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'max_depth' : [10,15,20],\n",
    "        }\n",
    "        grid_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring=scoring)\n",
    "        grid_rf.fit(X_train, y_train)\n",
    "        print(\"Completed. Time_used: \" + str(int(time.time()-start)) + 's, best score: ' + str(grid_rf.best_score_))\n",
    "        opt_params['rf'] = grid_rf.best_params_\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #lightgbm model\n",
    "    if 'lgb' in models:\n",
    "        print('Start training LightGBM model.')\n",
    "        start = time.time()\n",
    "        lgb_m = lgb.LGBMClassifier(objective = 'binary', n_jobs = 1, random_state=random_state)\n",
    "        param_grid_lgb = {\n",
    "            'n_estimators': [200*i for i in range(1, 6)],\n",
    "            'max_depth' : [5,6, 7, 8],\n",
    "            'num_leaves': range(10,40,5)\n",
    "        }\n",
    "        grid_lgb = GridSearchCV(lgb_m, param_grid_lgb, cv=5, scoring=scoring)\n",
    "        grid_lgb.fit(X_train, y_train)\n",
    "        print(\"Completed. Time_used: \" + str(int(time.time()-start)) + 's, best score: ' + str(grid_lgb.best_score_))\n",
    "        opt_params['lgb'] = grid_lgb.best_params_\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #SVM model\n",
    "    if 'svm' in models:\n",
    "        print('Start training SVM model.')\n",
    "        start = time.time()\n",
    "        svm = SVC(kernel='rbf', random_state=0)    \n",
    "        param_grid_svm = {'gamma': [1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
    "                         'C': [1, 10, 100, 1000, 10000]}\n",
    "        grid_svm = GridSearchCV(svm, param_grid_svm, cv=5, scoring=scoring)\n",
    "        grid_svm.fit(X_train, y_train)\n",
    "        print(\"Completed. Time_used: \" + str(int(time.time()-start)) + 's, best score: ' + str(grid_svm.best_score_))\n",
    "        opt_params['svm'] = grid_svm.best_params_\n",
    "    \n",
    "    return opt_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Start training LightGBM model.\n",
      "Completed. Time_used: 6143s, best score: 0.10758692045932304\n",
      "\n",
      "\n",
      "Start training SVM model.\n",
      "Completed. Time_used: 623s, best score: 0.268568358732892\n"
     ]
    }
   ],
   "source": [
    "opt_params_mg = model_training(X_mg, y_mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Start training LightGBM model.\n",
      "Completed. Time_used: 5027s, best score: 0.08151179687028483\n",
      "\n",
      "\n",
      "Start training SVM model.\n",
      "Completed. Time_used: 325s, best score: 0.2703067085658053\n"
     ]
    }
   ],
   "source": [
    "opt_params_ff = model_training(X_ff, y_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Start training LightGBM model.\n",
      "Completed. Time_used: 5349s, best score: 0.18059824138179376\n",
      "\n",
      "\n",
      "Start training SVM model.\n",
      "Completed. Time_used: 346s, best score: 0.3106627538153659\n"
     ]
    }
   ],
   "source": [
    "opt_params_mf = model_training(X_mf, y_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgb': {'max_depth': 10, 'n_estimators': 1000, 'num_leaves': 10},\n",
       " 'svm': {'C': 10000, 'gamma': 0.001}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgb': {'max_depth': 15, 'n_estimators': 400, 'num_leaves': 15},\n",
       " 'svm': {'C': 10000, 'gamma': 0.0001}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params_mg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgb': {'max_depth': 10, 'n_estimators': 800, 'num_leaves': 10},\n",
       " 'svm': {'C': 10000, 'gamma': 0.001}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params_ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Ensemble model and model measurement\n",
    "Train lightgbm model and svm model based on the optimal set of parameters, combine two classfication model to ensure stability, and measure the performance of combined model by using F1, recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opt_model(X_train, y_train, params, random_state = None):\n",
    "    \n",
    "\n",
    "    # Logistics Regression\n",
    "    #opt_lr = LogisticRegression(random_state=random_state, n_jobs = -1, C = params['lr']['C'])\n",
    "    #opt_lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Random Forest\n",
    "    #opt_rf = RandomForestClassifier(random_state=random_state, n_jobs = -1, n_estimators = params['rf']['n_estimators'], max_features = params['rf']['max_features'], max_depth = params['rf']['max_depth'], criterion = params['rf']['criterion'])\n",
    "    #opt_rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Lightgbm\n",
    "    opt_lgb = lgb.LGBMClassifier(objective = 'binary', n_jobs = 1, random_state=random_state, n_estimators = params['lgb']['n_estimators'], max_depth = params['lgb']['max_depth'], num_leaves = params['lgb']['num_leaves'])\n",
    "    opt_lgb.fit(X_train, y_train)\n",
    "    \n",
    "    # svm\n",
    "    opt_svm = SVC(kernel='rbf', random_state=random_state, gamma = params['svm']['gamma'], C = params['svm']['C'], probability=True)\n",
    "    opt_svm.fit(X_train, y_train)\n",
    "    \n",
    "    #return opt_lr, opt_rf, opt_lgb, opt_svm\n",
    "    return opt_lgb, opt_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict_prob(X_test, weights, opt_lgb, opt_svm):\n",
    "    # predict prob\n",
    "    #opt_lr_prob = opt_lr.predict_proba(X_test)\n",
    "    #opt_rf_prob = opt_rf.predict_proba(X_test)\n",
    "    opt_lgb_prob = opt_lgb.predict_proba(X_test)\n",
    "    opt_svm_prob = opt_svm.predict_proba(X_test)\n",
    "    \n",
    "    # ensemble\n",
    "    y_prob = np.array([opt_lgb_prob[i][1] * weights['lgb'] + opt_svm_prob[i][1] * weights['svm'] for i in range(X_test.shape[0])])\n",
    "\n",
    "    return y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_measure(X, y, params, random_state, weights, threshold):\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=random_state)\n",
    "    \n",
    "    opt_lgb, opt_svm = opt_model(X_train, y_train, params, random_state = random_state)\n",
    "    \n",
    "    y_prob = predict_prob(X_valid, weights, opt_lgb, opt_svm)\n",
    "    \n",
    "    threshold_value = sorted(y_prob, reverse = True)[int(len(y_prob) * threshold)]\n",
    "    y_pred = np.where(y_prob > threshold_value, 1, 0).astype(bool)\n",
    "    \n",
    "    print('recall rate: ' + str(recall_score(y_valid, y_pred)))\n",
    "    print('precision rate: ' + str(precision_score(y_valid, y_pred)))\n",
    "    print('f1_score' + str(f1_score(y_valid, y_pred)))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall rate: 0.9080459770114943\n",
      "precision rate: 0.22931785195936139\n",
      "f1_score0.36616454229432216\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "weights_ff = {'lgb': 0.3, 'svm': 0.7}\n",
    "%time model_measure(X_ff, y_ff, opt_params_ff, 0, weights_ff, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall rate: 0.9291666666666667\n",
      "precision rate: 0.23773987206823027\n",
      "f1_score0.37860780984719866\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "weights_mg = {'lgb': 0.3, 'svm': 0.7}\n",
    "%time model_measure(X_mg, y_mg, opt_params_mg, 0, weights_mg, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall rate: 0.914572864321608\n",
      "precision rate: 0.2633863965267728\n",
      "f1_score0.40898876404494383\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "weights_mf = {'lgb': 0.3, 'svm': 0.7}\n",
    "%time model_measure(X_mf, y_mf, opt_params_mf, 0, weights_mf, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv', encoding = 'utf-8')\n",
    "ff_test = df[df['Category'] == 'Female Clothes'].reset_index()\n",
    "mg_test = df[df['Category'] == 'Mobile & Gadgets'].reset_index()\n",
    "mf_test = df[df['Category'] == 'Male Clothes'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(df, word2vec_file, word_info, weights, opt_lgb, opt_svm, threshold = 3):\n",
    "    \n",
    "    model, keys, wordvector = read_word2vec(word2vec_file)\n",
    "    \n",
    "    # processing text data\n",
    "    df['Product_Name_t'] = df.apply(lambda row: pre_processing(row['Product Name'], mode = 'traditional'), axis = 1)\n",
    "    df['Product_Name_s'] = df.apply(lambda row: pre_processing(row['Product Name'], mode = 'simplified'), axis = 1)\n",
    "\n",
    "    # construct (title, keyword) pairs\n",
    "    n = df.shape[0]\n",
    "    lines = []\n",
    "    for i in range(n):\n",
    "        name = df['Product_Name_t'][i]\n",
    "        words = name.strip().split()\n",
    "        for word in words:\n",
    "            lines.append([df['Product Name'][i], word])\n",
    "            \n",
    "    df_test = pd.DataFrame(lines)\n",
    "    df_test.columns = ['Product Name', 'Query']\n",
    "    \n",
    "    df_test = data_prep(df_test)\n",
    "    \n",
    "    # Vectorize text into word vector\n",
    "    X = construct_input_X(df_test, word2vec_file, word_info)\n",
    "\n",
    "    # predict probability based on ensemble model\n",
    "    y_prob = predict_prob(X, weights, opt_lgb, opt_svm)\n",
    "    \n",
    "    df_test['predict_prob'] = y_prob\n",
    "\n",
    "    # sort a list of keywords based on the predicted probability\n",
    "    lines = []\n",
    "    for product in df_test['Product Name'].unique().tolist():\n",
    "        sub = df_test[df_test['Product Name'] == product].reset_index()\n",
    "        word_list = sub.sort_values(by = 'predict_prob', ascending = False).Query_t.tolist()\n",
    "        words = []\n",
    "        seen = set()\n",
    "        for ele in word_list:\n",
    "            if ele not in seen:\n",
    "                words.append(ele)\n",
    "            seen.add(ele)\n",
    "        text = ';'.join(words)\n",
    "        lines.append([product, text])\n",
    "        \n",
    "    res = pd.DataFrame(lines)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_mg, y_mg, random_state=0)\n",
    "opt_lgb, opt_svm = opt_model(X_train, y_train, opt_params_mg, random_state = 0)\n",
    "%time prediction = make_prediction(mg_test, 'model_mg', word_info_mg, weights_mg,opt_lgb, opt_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction.to_csv('prediction_mg2.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 17s\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_ff, y_ff, random_state=0)\n",
    "opt_lgb, opt_svm = opt_model(X_train, y_train, opt_params_ff, random_state = 0)\n",
    "%time prediction = make_prediction(ff_test, 'model_ff', word_info_ff, weights_ff,opt_lgb, opt_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction.to_csv('prediction_ff2.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 51s\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_mf, y_mf, random_state=0)\n",
    "opt_lgb, opt_svm = opt_model(X_train, y_train, opt_params_mf, random_state = 0)\n",
    "%time prediction = make_prediction(mf_test, 'model_mf', word_info_mf, weights_mf,opt_lgb, opt_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction.to_csv('prediction_mf3.csv', encoding = 'utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
