{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from gensim.models import word2vec\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Define a function to train word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Word2Vec(df):\n",
    "    sentences = [Product_Name.strip().split() for Product_Name in df['Product_Name_s'].tolist()]\n",
    "    \n",
    "    window = df.apply(lambda row: len(row['Product_Name_s'].split()), axis = 1).max()\n",
    "    \n",
    "    model = word2vec.Word2Vec(sentences, min_count=1,  window = window, sg = 1)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ff_train = pd.read_csv('ff_train.csv', encoding = 'utf-8')\n",
    "mg_train = pd.read_csv('mg_train.csv', encoding = 'utf-8')\n",
    "mf_train = pd.read_csv('mf_train.csv', encoding = 'utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 For titles of 'male fashion' products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-03 19:04:11,262 : INFO : collecting all words and their counts\n",
      "2018-04-03 19:04:11,263 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-03 19:04:11,281 : INFO : collected 6604 word types from a corpus of 41241 raw words and 3070 sentences\n",
      "2018-04-03 19:04:11,284 : INFO : Loading a fresh vocabulary\n",
      "2018-04-03 19:04:11,311 : INFO : min_count=1 retains 6604 unique words (100% of original 6604, drops 0)\n",
      "2018-04-03 19:04:11,314 : INFO : min_count=1 leaves 41241 word corpus (100% of original 41241, drops 0)\n",
      "2018-04-03 19:04:11,356 : INFO : deleting the raw counts dictionary of 6604 items\n",
      "2018-04-03 19:04:11,359 : INFO : sample=0.001 downsamples 54 most-common words\n",
      "2018-04-03 19:04:11,362 : INFO : downsampling leaves estimated 37124 word corpus (90.0% of prior 41241)\n",
      "2018-04-03 19:04:11,397 : INFO : estimated required memory for 6604 words and 100 dimensions: 8585200 bytes\n",
      "2018-04-03 19:04:11,401 : INFO : resetting layer weights\n",
      "2018-04-03 19:04:11,547 : INFO : training model with 3 workers on 6604 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=27\n",
      "2018-04-03 19:04:11,796 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:11,813 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:11,959 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:11,961 : INFO : EPOCH - 1 : training on 41241 raw words (37096 effective words) took 0.4s, 91387 effective words/s\n",
      "2018-04-03 19:04:12,219 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:12,237 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:12,452 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:12,455 : INFO : EPOCH - 2 : training on 41241 raw words (37060 effective words) took 0.5s, 77400 effective words/s\n",
      "2018-04-03 19:04:12,768 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:12,795 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:12,993 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:12,995 : INFO : EPOCH - 3 : training on 41241 raw words (37057 effective words) took 0.5s, 73113 effective words/s\n",
      "2018-04-03 19:04:13,379 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:13,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:13,699 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:13,702 : INFO : EPOCH - 4 : training on 41241 raw words (37054 effective words) took 0.7s, 54591 effective words/s\n",
      "2018-04-03 19:04:14,214 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:14,245 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:14,562 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:14,568 : INFO : EPOCH - 5 : training on 41241 raw words (37119 effective words) took 0.8s, 44082 effective words/s\n",
      "2018-04-03 19:04:14,574 : INFO : training on a 206205 raw words (185386 effective words) took 3.0s, 61274 effective words/s\n",
      "2018-04-03 19:04:14,577 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2018-04-03 19:04:14,588 : INFO : saving Word2Vec object under model_mf.model, separately None\n",
      "2018-04-03 19:04:14,590 : INFO : not storing attribute vectors_norm\n",
      "2018-04-03 19:04:14,593 : INFO : not storing attribute cum_table\n",
      "2018-04-03 19:04:14,744 : INFO : saved model_mf.model\n"
     ]
    }
   ],
   "source": [
    "model_mf = train_Word2Vec(mf_train)\n",
    "model_mf.save('model_mf.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 For titles of 'mobile & gadget' products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-03 19:04:15,040 : INFO : collecting all words and their counts\n",
      "2018-04-03 19:04:15,043 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-03 19:04:15,077 : INFO : collected 7418 word types from a corpus of 56878 raw words and 4169 sentences\n",
      "2018-04-03 19:04:15,079 : INFO : Loading a fresh vocabulary\n",
      "2018-04-03 19:04:15,214 : INFO : min_count=1 retains 7418 unique words (100% of original 7418, drops 0)\n",
      "2018-04-03 19:04:15,219 : INFO : min_count=1 leaves 56878 word corpus (100% of original 56878, drops 0)\n",
      "2018-04-03 19:04:15,287 : INFO : deleting the raw counts dictionary of 7418 items\n",
      "2018-04-03 19:04:15,290 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2018-04-03 19:04:15,292 : INFO : downsampling leaves estimated 50337 word corpus (88.5% of prior 56878)\n",
      "2018-04-03 19:04:15,350 : INFO : estimated required memory for 7418 words and 100 dimensions: 9643400 bytes\n",
      "2018-04-03 19:04:15,357 : INFO : resetting layer weights\n",
      "2018-04-03 19:04:15,579 : INFO : training model with 3 workers on 7418 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=46\n",
      "2018-04-03 19:04:16,162 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:16,204 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:16,225 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:16,227 : INFO : EPOCH - 1 : training on 56878 raw words (50379 effective words) took 0.6s, 79745 effective words/s\n",
      "2018-04-03 19:04:16,954 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:16,972 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:16,975 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:16,977 : INFO : EPOCH - 2 : training on 56878 raw words (50350 effective words) took 0.7s, 69966 effective words/s\n",
      "2018-04-03 19:04:17,777 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:17,792 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:17,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:17,812 : INFO : EPOCH - 3 : training on 56878 raw words (50358 effective words) took 0.8s, 63923 effective words/s\n",
      "2018-04-03 19:04:18,589 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:18,623 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:18,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:18,645 : INFO : EPOCH - 4 : training on 56878 raw words (50406 effective words) took 0.8s, 64933 effective words/s\n",
      "2018-04-03 19:04:19,315 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:19,352 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:19,386 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:19,390 : INFO : EPOCH - 5 : training on 56878 raw words (50378 effective words) took 0.7s, 72946 effective words/s\n",
      "2018-04-03 19:04:19,397 : INFO : training on a 284390 raw words (251871 effective words) took 3.8s, 66001 effective words/s\n",
      "2018-04-03 19:04:19,407 : INFO : saving Word2Vec object under model_mg.model, separately None\n",
      "2018-04-03 19:04:19,412 : INFO : not storing attribute vectors_norm\n",
      "2018-04-03 19:04:19,416 : INFO : not storing attribute cum_table\n",
      "2018-04-03 19:04:19,588 : INFO : saved model_mg.model\n"
     ]
    }
   ],
   "source": [
    "model_mg = train_Word2Vec(mg_train)\n",
    "model_mg.save('model_mg.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 For titles of 'female fashion' products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-03 19:04:19,813 : INFO : collecting all words and their counts\n",
      "2018-04-03 19:04:19,815 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-03 19:04:19,838 : INFO : collected 6244 word types from a corpus of 45502 raw words and 3064 sentences\n",
      "2018-04-03 19:04:19,843 : INFO : Loading a fresh vocabulary\n",
      "2018-04-03 19:04:19,878 : INFO : min_count=1 retains 6244 unique words (100% of original 6244, drops 0)\n",
      "2018-04-03 19:04:19,881 : INFO : min_count=1 leaves 45502 word corpus (100% of original 45502, drops 0)\n",
      "2018-04-03 19:04:19,933 : INFO : deleting the raw counts dictionary of 6244 items\n",
      "2018-04-03 19:04:19,936 : INFO : sample=0.001 downsamples 57 most-common words\n",
      "2018-04-03 19:04:19,950 : INFO : downsampling leaves estimated 39259 word corpus (86.3% of prior 45502)\n",
      "2018-04-03 19:04:19,984 : INFO : estimated required memory for 6244 words and 100 dimensions: 8117200 bytes\n",
      "2018-04-03 19:04:19,987 : INFO : resetting layer weights\n",
      "2018-04-03 19:04:20,223 : INFO : training model with 3 workers on 6244 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=45\n",
      "2018-04-03 19:04:20,635 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:20,768 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:20,915 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:20,917 : INFO : EPOCH - 1 : training on 45502 raw words (39313 effective words) took 0.7s, 60402 effective words/s\n",
      "2018-04-03 19:04:21,335 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:21,500 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:21,628 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:21,630 : INFO : EPOCH - 2 : training on 45502 raw words (39354 effective words) took 0.7s, 60190 effective words/s\n",
      "2018-04-03 19:04:22,046 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:22,214 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:22,312 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:22,315 : INFO : EPOCH - 3 : training on 45502 raw words (39259 effective words) took 0.6s, 61854 effective words/s\n",
      "2018-04-03 19:04:22,733 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:22,895 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:22,971 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:22,973 : INFO : EPOCH - 4 : training on 45502 raw words (39181 effective words) took 0.6s, 64896 effective words/s\n",
      "2018-04-03 19:04:23,437 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-03 19:04:23,582 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-03 19:04:23,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-03 19:04:23,689 : INFO : EPOCH - 5 : training on 45502 raw words (39242 effective words) took 0.7s, 59483 effective words/s\n",
      "2018-04-03 19:04:23,691 : INFO : training on a 227510 raw words (196349 effective words) took 3.5s, 56716 effective words/s\n",
      "2018-04-03 19:04:23,694 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2018-04-03 19:04:23,703 : INFO : saving Word2Vec object under model_ff.model, separately None\n",
      "2018-04-03 19:04:23,705 : INFO : not storing attribute vectors_norm\n",
      "2018-04-03 19:04:23,708 : INFO : not storing attribute cum_table\n",
      "2018-04-03 19:04:23,817 : INFO : saved model_ff.model\n"
     ]
    }
   ],
   "source": [
    "model_ff = train_Word2Vec(ff_train)\n",
    "model_ff.save('model_ff.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Reviewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8605663887251421\n",
      "0.7665001355901444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\abc\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\abc\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(model_ff.similarity('短裤','长裤'))\n",
    "print(model_ff.similarity('短裤','t恤'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\abc\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('素t', 0.9832006692886353),\n",
       " ('短袖上衣', 0.9797725677490234),\n",
       " ('圆领', 0.977285623550415),\n",
       " ('短袖t恤', 0.9683908224105835),\n",
       " ('短袖', 0.9616423845291138),\n",
       " ('宽松短袖', 0.9612372517585754),\n",
       " ('衣服', 0.960029125213623),\n",
       " ('打底衫', 0.9598938822746277),\n",
       " ('韩范', 0.9583677649497986),\n",
       " ('字母', 0.9565817713737488)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ff.most_similar(['t恤'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\abc\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2018-04-03 19:04:23,949 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('软壳', 0.9073449373245239),\n",
       " ('保护壳', 0.8957708477973938),\n",
       " ('防摔壳', 0.8705962896347046),\n",
       " ('防摔', 0.8630738258361816),\n",
       " ('加厚', 0.845794677734375),\n",
       " ('英文', 0.8428493142127991),\n",
       " ('辛普森', 0.842496395111084),\n",
       " ('少女', 0.8423134088516235),\n",
       " ('原宿', 0.8413721323013306),\n",
       " ('渐层', 0.8407720923423767)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mg.most_similar(['手机壳'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\abc\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2018-04-03 19:04:24,020 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('海滩裤', 0.9694491028785706),\n",
       " ('五分裤', 0.9669184684753418),\n",
       " ('休闲', 0.9435919523239136),\n",
       " ('休閒短裤', 0.9359419345855713),\n",
       " ('松紧', 0.9226898550987244),\n",
       " ('中裤', 0.9216972589492798),\n",
       " ('时尚', 0.920397162437439),\n",
       " ('绑带', 0.9201370477676392),\n",
       " ('韩系', 0.9176990985870361),\n",
       " ('五分短裤', 0.9129565954208374)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mf.most_similar(['沙滩裤'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\abc\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.19924697,  0.6276916 , -0.08995506,  0.32426256, -0.04493741,\n",
       "        0.3257724 , -0.17402256, -0.27104753, -0.17894614,  0.10198706,\n",
       "       -0.27319348,  0.02146268, -0.16099626, -0.47675055, -0.15807314,\n",
       "       -0.47139677, -0.5648258 ,  0.4939753 ,  0.10391641,  0.13731194,\n",
       "       -0.21126764,  0.3107965 , -0.03591251,  0.76509726,  0.558321  ,\n",
       "       -0.0936106 ,  0.07412483,  0.23064597, -0.33411935,  0.08496652,\n",
       "        0.04709025,  0.13435403, -0.25183725, -0.46391034,  0.39573026,\n",
       "        0.29214576,  0.33173665, -0.4364207 , -0.12067068,  0.6887042 ,\n",
       "        0.3636579 ,  0.10469751,  0.2157699 ,  0.1632134 ,  0.12865828,\n",
       "       -0.01313473, -0.4635576 , -0.18016255, -0.11433658,  0.15676758,\n",
       "        0.6672143 , -0.0509435 , -0.24562328, -0.02731759,  0.09797992,\n",
       "        0.33072612, -0.08965809,  0.1328719 ,  0.37181646, -0.07301752,\n",
       "        0.13087064, -0.03873652,  0.255346  ,  0.09856891,  0.20357797,\n",
       "       -0.14227699, -0.36370927,  0.34647298,  0.05255154, -0.09358515,\n",
       "       -0.07765438, -0.0247015 ,  0.4150568 ,  0.34598097, -0.31986192,\n",
       "        0.09350455,  0.46886972, -0.04784348,  0.47351438,  0.6304188 ,\n",
       "       -0.29010072,  0.08178405,  0.00810536,  0.09227429,  0.16315848,\n",
       "        0.05709928,  0.15148684, -0.0499129 , -0.18069607, -0.3709761 ,\n",
       "       -0.18602255, -0.22547792,  0.05353151,  0.5187604 , -0.14109352,\n",
       "        0.33225417,  0.11340243,  0.1455952 ,  0.16667709,  0.01390105],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mf['沙滩裤']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
